{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "import pyproj\n",
    "from datetime import datetime\n",
    "from osgeo import gdal, gdalconst, osr\n",
    "from utils import interp2d\n",
    "\n",
    "from osgeo import gdal, gdalconst, osr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from descartes.patch import PolygonPatch\n",
    "from matplotlib import path, patches\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "#plt.ticklabel_format(useOffset=False)\n",
    "\n",
    "#data_dir='ATL06/Byrd_glacier_rel001/'\n",
    "\n",
    "lon_lat=pyproj.Proj(init='epsg:4326')\n",
    "polar_stereo=pyproj.Proj(init='epsg:3031')\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "# make sure we're dealing with the most recent version of any code we're using\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "\n",
    "def ATL06_to_dict(filename, dataset_dict, gpstime=True):\n",
    "    \"\"\"\n",
    "        Read selected datasets from an ATL06 file\n",
    "\n",
    "        Input arguments:\n",
    "            filename: ATl06 file to read\n",
    "            dataset_dict: A dictinary describing the fields to be read\n",
    "                    keys give the group names to be read, \n",
    "                    entries are lists of datasets within the groups\n",
    "            gpstime: boolean; correct times for GPS epoch (default true)\n",
    "        Output argument:\n",
    "            D6: dictionary containing ATL06 data.  Each dataset in \n",
    "                dataset_dict has its own entry in D6.  Each dataset \n",
    "                in D6 contains a list of numpy arrays containing the \n",
    "                data\n",
    "    \"\"\"\n",
    "    \n",
    "    D6=[]\n",
    "    pairs=[1, 2, 3]\n",
    "    beams=['l','r']\n",
    "    gps_epoch = datetime(1980, 1, 6, 0, 0, 0)\n",
    "    gps_epoch_ts = gps_epoch.timestamp()\n",
    "    # open the HDF5 file\n",
    "    with h5py.File(filename) as h5f:\n",
    "        if gpstime: #calc the time offset to unix time\n",
    "            file_epoch_time = np.array(h5f['ancillary_data']['atlas_sdp_gps_epoch']) + gps_epoch_ts\n",
    "        else:\n",
    "            file_epoch_time = 0\n",
    "        \n",
    "        # loop over beam pairs\n",
    "        for pair in pairs:\n",
    "            # loop over beams\n",
    "            for beam_ind, beam in enumerate(beams):\n",
    "                # check if a beam exists, if not, skip it\n",
    "                if '/gt%d%s/land_ice_segments' % (pair, beam) not in h5f:\n",
    "                    continue\n",
    "                # loop over the groups in the dataset dictionary\n",
    "                temp={}\n",
    "                for group in dataset_dict.keys():\n",
    "                    for dataset in dataset_dict[group]:\n",
    "                        DS='/gt%d%s/%s/%s' % (pair, beam, group, dataset)\n",
    "                        # since a dataset may not exist in a file, we're going to try to read it, and if it doesn't work, we'll move on to the next:\n",
    "                        try:\n",
    "                            temp[dataset]=np.array(h5f[DS])\n",
    "                            if dataset == \"delta_time\":\n",
    "                                temp[dataset] = temp[dataset] + file_epoch_time\n",
    "                            # some parameters have a _FillValue attribute.  If it exists, use it to identify bad values, and set them to np.NaN\n",
    "                            if '_FillValue' in h5f[DS].attrs:\n",
    "                                fill_value=h5f[DS].attrs['_FillValue']\n",
    "                                bad = temp[dataset] == fill_value\n",
    "                                temp[dataset] = np.float64(temp[dataset])\n",
    "                                temp[dataset][temp[dataset]==fill_value]=np.NaN\n",
    "                        except KeyError as e:\n",
    "                            pass\n",
    "                if len(temp) > 0:\n",
    "                    # it's sometimes convenient to have the beam and the pair as part of the output data structure: This is how we put them there.\n",
    "                    temp['pair']=np.zeros_like(temp['h_li'])+pair\n",
    "                    temp['beam']=np.zeros_like(temp['h_li'])+beam_ind\n",
    "                    temp['filename']=filename\n",
    "                    D6.append(temp)\n",
    "    return D6\n",
    "\n",
    "def get_velocity(x, y, vx, vy, D6):\n",
    "    psx,psy = pyproj.transform(lon_lat,polar_stereo,D6['longitude'],D6['latitude'])\n",
    "    vel_x = interp2d(x, y, vx, psx, psy, order=1)\n",
    "    vel_y = interp2d(x, y, vy, psx, psy, order=1)\n",
    "    vdir = np.rad2deg(np.arctan2(vel_x, vel_y))%360.\n",
    "    return vdir\n",
    "\n",
    "def get_rema_elev(x, y, rarr, D6):\n",
    "    psx,psy = pyproj.transform(lon_lat,polar_stereo,D6['longitude'],D6['latitude'])\n",
    "    rema_is2 = interp2d(x,y,rarr, psx, psy, order=1)\n",
    "    return rema_is2\n",
    "  \n",
    "\n",
    "def tifread(ifile):\n",
    "    file = gdal.Open(ifile, gdal.GA_ReadOnly)\n",
    "    metaData = file.GetMetadata()\n",
    "    projection = file.GetProjection()\n",
    "    src = osr.SpatialReference()\n",
    "    src.ImportFromWkt(projection)\n",
    "    proj = src.ExportToWkt()\n",
    "\n",
    "    Nx = file.RasterXSize\n",
    "    Ny = file.RasterYSize\n",
    "    \n",
    "    trans = file.GetGeoTransform()\n",
    "\n",
    "    dx = trans[1]\n",
    "    dy = trans[5]\n",
    "\n",
    "    Xp = np.arange(Nx)\n",
    "    Yp = np.arange(Ny)\n",
    "\n",
    "    (Xp, Yp) = np.meshgrid(Xp, Yp)\n",
    "\n",
    "    X = trans[0] + (Xp + 0.5) * trans[1] + (Yp + 0.5) * trans[2]\n",
    "    Y = trans[3] + (Xp + 0.5) * trans[4] + (Yp + 0.5) * trans[5]\n",
    "\n",
    "    band = file.GetRasterBand(1)\n",
    "    Z = band.ReadAsArray()\n",
    "    dx = np.abs(dx)\n",
    "    dy = np.abs(dy)\n",
    "    return X, Y, Z\n",
    "\n",
    "    \n",
    "def findGL(D6):\n",
    "    \"\"\"Return array of indices of intersection of Grounding Zone and ATL06\n",
    "       Return polygon of the GL\n",
    "      \"\"\"\n",
    "    #shapefile = gpd.read_file(\"./data/GL_VARIABILITY.shp\")\n",
    "    ## read the grounding line - which is a multi-polygon\n",
    "    ## and find the largest polygon\n",
    "    gl_fn = './data/IMBIE/GroundingLine_Antarctica_v02.shp'\n",
    "    #imbie_gdf = gpd.read_file(imbie_fn)\n",
    "    gl_gdf = gpd.read_file(gl_fn)\n",
    "    geom0=gl_gdf['geometry'][0]\n",
    "    #len(geom0)\n",
    "    areas = [i.area for i in geom0]\n",
    "    largest = np.argmax(areas)\n",
    "    polygon = geom0[largest]\n",
    "    \n",
    "#     for polygon in shapefile.geometry:\n",
    "#        patch = PolygonPatch(polygon)\n",
    "#        xp, yp = polygon.exterior.coords.xy\n",
    "#        coords = np.squeeze(np.dstack((xp,yp)))\n",
    "#        #plt.plot(*polygon.exterior.xy);\n",
    "#     polygon = shapefile.geometry[0] # Item number can be changed for\n",
    "    xp, yp = polygon.exterior.coords.xy\n",
    "    coords = np.squeeze(np.dstack((xp,yp)))\n",
    "    poly_mpl = path.Path(coords)\n",
    "    temp = {}\n",
    "    temp[\"x\"],temp[\"y\"] = pyproj.transform(lon_lat,polar_stereo,D6[\"longitude\"],D6[\"latitude\"])\n",
    "    mask = poly_mpl.contains_points(np.transpose([temp[\"x\"],temp[\"y\"]]))\n",
    "    #plt.plot(*polygon.exterior.xy)\n",
    "    #plt.plot(temp[‘x’],temp[‘y’])\n",
    "    cross=np.argwhere(mask)\n",
    "    return cross, polygon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrk(fn):\n",
    "    \"\"\"Load track file, fn and return a tuple (D6_list, T6_list) each is a list of dicts.\n",
    "    List idx is the beam number\n",
    "    D6_list item is a dict with h_li:array, time:array, longitude: latitude: x_atc:\n",
    "    T6_list item has latitude: lontitude: tide: time:\n",
    "    \"\"\"\n",
    "    print(\"Loading file: \", fn)\n",
    "    fn = ATLfiles[trkno]\n",
    "    \n",
    "    fbase, ext = os.path.splitext(fn)\n",
    "    ftide = fbase+\"_tides_cats\" + ext\n",
    "    \n",
    "    T6_list=[]\n",
    "    with h5py.File(ftide) as tidef:\n",
    "        trks = tidef.keys()\n",
    "        for i, trk in enumerate(trks):\n",
    "            tmp={}\n",
    "            tmp[\"latitude\"] = np.array(tidef[f\"/{trk}/lat\"]).T\n",
    "            tmp[\"longitude\"] = np.array(tidef[f\"/{trk}/lon\"]).T\n",
    "            tmp[\"tide\"] = np.array(tidef[f\"/{trk}/tides_cats\"]).T\n",
    "            tmp[\"time\"] = np.array(tidef[f\"/{trk}/time\"]).T\n",
    "\n",
    "            T6_list.append(tmp)\n",
    "            #print(trk, lat)\n",
    "    #print(T6_list[0])          \n",
    "    \n",
    "    dataset_dict={'land_ice_segments':['h_li', 'delta_time','longitude','latitude'], \n",
    "                  'land_ice_segments/ground_track':['x_atc', 'ref_azimuth']}\n",
    "    # read ATL06 into a dictionary (the ATL06 file has the same name as the ATL03 file, except for the product name)\n",
    "    D6_list=ATL06_to_dict(fn, dataset_dict)\n",
    "    return D6_list, T6_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMap(D6_list, beam):\n",
    "    \"\"\"Plot the REMA surface with the grounding line and ATL06 track overlaid\n",
    "    BUG: needs to have rema_xx and poly loaded already\n",
    "    \"\"\"\n",
    "    ext = rema_xI[0][0], rema_xI[0][-1], rema_yI[-1][0], rema_yI[0][0]\n",
    "    fm, axm = plt.subplots()\n",
    "    im = axm.imshow(rema_array, extent=ext, cmap=\"coolwarm\", vmin=0, vmax=2500)\n",
    "    #axm.set_xlim(-2.5e6, -1e6)\n",
    "    #axm.set_ylim(-1e6, .5e6)\n",
    "    divider = make_axes_locatable(axm)\n",
    "    cax = divider.append_axes(\"right\", size=\"2.5%\", pad=0.3)\n",
    "    cb=plt.colorbar(im,cax=cax)\n",
    "        \n",
    "    D6 = D6_list[beam]\n",
    "    psx,psy = pyproj.transform(lon_lat,polar_stereo,D6['longitude'],D6['latitude'])\n",
    "\n",
    "    axm.plot(psx, psy, color=\"black\")\n",
    "    axm.plot(*poly.exterior.xy, color=\"#d47500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRes(D6_list, T6_list, beam):\n",
    "    \"\"\"plot the results for this beam\n",
    "    Fig 1 - ATL06 elevation and tide\n",
    "    Fig 2 - ATL06 and REMA elevations\n",
    "    Fig 3 - Difference between ATL06 and REMA\n",
    "    Fig 4 - Ice flow speed azimuth (TODO: add ATL06 track azimuth)\n",
    "    \"\"\"\n",
    "    D6 = D6_list[beam]\n",
    "    if len(T6_list) > 0:\n",
    "        T6 = T6_list[beam]\n",
    "    rema_elev = get_rema_elev(rema_xI, rema_yI, rema_array, D6)\n",
    "    vels = get_velocity(vels_xI, vels_yI, vels_array_x, vels_array_y, D6)\n",
    "\n",
    "\n",
    "    #axes.color_cycle    : 332288, 88CCEE, 44AA99, 117733, 999933, DDCC77, CC6677, 882255, AA4499\n",
    "\n",
    "    f1,ax = plt.subplots(4,1, figsize=(10,6), sharex=True)\n",
    "    ax[0].plot(D6['x_atc'], D6['h_li'],'r.', markersize=1, label='ATL06', color=\"#332288\")\n",
    "    if len(T6_list) > 0:\n",
    "        ax[0].plot(D6['x_atc'], T6['tide'], color=\"#88CCEE\")\n",
    "    lgd = ax[0].legend(loc=3,frameon=False)\n",
    "    ax[0].set_ylim([-100,100])\n",
    "    ax[0].set_xlabel('x_atc, m')\n",
    "    ax[0].set_ylabel('h, m')\n",
    "    f = os.path.basename(D6['filename'])\n",
    "    ax[0].title.set_text('ATL06 h_li & Padman Tide h. File:' + f)\n",
    "    if len(crossing) > 0:\n",
    "        ax[0].axvline(D6['x_atc'][crossing[0]])\n",
    "        ax[0].axvline(D6['x_atc'][crossing[-1]])\n",
    "    #plt.savefig('thwt.png')\n",
    "    \n",
    "    \n",
    "    # plot results\n",
    "    #f2,ax2 = plt.subplots(312, sharex=True, sharey=True)\n",
    "    ax[1].plot(D6['x_atc'], D6['h_li'],'r.', markersize=1, color=\"#44AA99\", label='ATL06')\n",
    "    ax[1].plot(D6['x_atc'], rema_elev ,'b.', markersize=1, color=\"#117733\", label='REMA')\n",
    "    lgd = ax[1].legend(loc=3,frameon=False)\n",
    "    ax[1].set_ylim([-100,2000])\n",
    "    ax[1].set_xlabel('x_atc, m')\n",
    "    ax[1].set_ylabel('h, m')\n",
    "    ax[1].title.set_text('ATL06 h_li & REMA h')\n",
    "    \n",
    "    if len(crossing) > 0:\n",
    "        ax[1].axvline(D6['x_atc'][crossing[0]])\n",
    "        ax[1].axvline(D6['x_atc'][crossing[-1]])\n",
    "    #plt.savefig('thw0.png')\n",
    "    \n",
    "    #f3,ax3 = plt.subplots(313, sharex=True, sharey=True)\n",
    "    ax[2].plot(D6['x_atc'], D6['h_li']-rema_elev,'r.', markersize=1, color=\"#999933\", label='Difference IS2-REMA')\n",
    "    lgd = ax[2].legend(loc=3,frameon=False)\n",
    "    ax[2].set_ylim([-100,100])\n",
    "    ax[2].set_xlabel('x_atc, m')\n",
    "    ax[2].set_ylabel('h, m')\n",
    "    ax[2].title.set_text('Difference IS2-REMA')\n",
    "    \n",
    "    if len(crossing) > 0:\n",
    "        ax[2].axvline(D6['x_atc'][crossing[0]])\n",
    "        ax[2].axvline(D6['x_atc'][crossing[-1]])\n",
    "    \n",
    "    ax[3].plot(D6['x_atc'], vels ,'g.', markersize=1, color=\"#DDCC77\", label='Velocity')\n",
    "    ax[3].plot(D6['x_atc'], D6['ref_azimuth'], markersize=1, color=\"#CC6677\", label=\"Trk Az\")\n",
    "    ax[3].title.set_text('GOLIVE Ice flow & ATL06 Track azimuth')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if len(crossing) > 0:\n",
    "        ax[3].axvline(D6['x_atc'][crossing[0]])\n",
    "        ax[3].axvline(D6['x_atc'][crossing[-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/ground2float/data/ATL06/processed_ATL06_20181030052112_04820111_001_01.h5\n",
      "/home/jovyan/ground2float/data/ATL06/processed_ATL06_20181029182109_04750111_001_01.h5\n",
      "/home/jovyan/ground2float/data/ATL06/processed_ATL06_20181029054650_04670111_001_01.h5\n",
      "/home/jovyan/ground2float/data/ATL06/processed_ATL06_20181029041233_04660111_001_01.h5\n",
      "/home/jovyan/ground2float/data/ATL06/ATL06_20181105085653_05760110_001_01.h5\n",
      "/home/jovyan/ground2float/data/ATL06/processed_ATL06_20181030192949_04910111_001_01.h5\n",
      "/home/jovyan/ground2float/data/ATL06/ATL06_20181208072425_10790110_001_01.h5\n",
      "/home/jovyan/ground2float/data/ATL06/processed_ATL06_20181030175532_04900111_001_01.h5\n",
      "/home/jovyan/ground2float/data/ATL06/ATL06_20190204043645_05760210_001_01.h5\n",
      "/home/jovyan/ground2float/data/ATL06/processed_ATL06_20181030051331_04820110_001_01.h5\n",
      "/home/jovyan/ground2float/data/ATL06/processed_ATL06_20181029182653_04750112_001_01.h5\n",
      "/home/jovyan/ground2float/data/ATL06/processed_ATL06_20181029053909_04670110_001_01.h5\n",
      "/home/jovyan/ground2float/data/ATL06/processed_ATL06_20181030180115_04900112_001_01.h5\n",
      "Loading file:  /home/jovyan/ground2float/data/ATL06/processed_ATL06_20181029182109_04750111_001_01.h5\n",
      "Choosing beam: 2r(s)\n",
      "time of track: 2018-10-29 18:26:07.573233\n",
      "track len (npts): (17447,)\n",
      "[[    0]\n",
      " [    1]\n",
      " [    2]\n",
      " ...\n",
      " [10633]\n",
      " [10634]\n",
      " [10635]]\n",
      "index of track/gl cross: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6831b0d8542458a9c87cf7d7ab04bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fe9208822c4c9c862ceb353db36d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # get h5 files, velocity files, and rema\n",
    "    #os.system('aws --no-sign-request s3 sync s3://pangeo-data-upload-oregon/icesat2/ground2float/ ./data')\n",
    "    #os.system('echo $PATH')\n",
    "        \n",
    "    #lineno=898\n",
    "    #fn = \"/home/jovyan/ground2float/data/ATL06/ATL06_20181208072425_10790110_001_01.h5\" # file name for the line\n",
    "    data_dir = \"/home/jovyan/ground2float/data/ATL06/*01.h5\"\n",
    "    ATLfiles = glob(data_dir)\n",
    "    print(\"\\n\".join(ATLfiles))\n",
    "    \n",
    "    # change this to pick the track\n",
    "    trkno = 1\n",
    "    D6_list, T6_list = loadTrk(ATLfiles[trkno])\n",
    "\n",
    "    # change this to pick out the beam\n",
    "    beam = 3\n",
    "    beams=['1l(w)', '1r(s)', '2l(w)', '2r(s)', '3l(w)', '3r(s)']\n",
    "    print(\"Choosing beam:\", beams[beam])\n",
    "    D6 = D6_list[beam]\n",
    "    print(\"time of track:\", datetime.utcfromtimestamp(D6['delta_time'][0]))\n",
    "    if len(T6_list) > 0:\n",
    "        T6 = T6_list[beam]\n",
    "\n",
    "    print(\"track len (npts):\", D6['x_atc'].shape)\n",
    "    #print(T6['tide'].shape)\n",
    "    crossing, poly = findGL(D6)\n",
    "    print(crossing)\n",
    "    if len(crossing) > 0:\n",
    "        print(\"index of track/gl cross:\", crossing[0])\n",
    "    else:\n",
    "        print(\"no crossing\")\n",
    "    # load in velocity and subsample\n",
    "    vels_xI,vels_yI,vels_array_x=tifread('./data/vx.tif')\n",
    "    vels_xI,vels_yI,vels_array_y=tifread('./data/vy.tif')\n",
    "\n",
    "    vels = get_velocity(vels_xI, vels_yI, vels_array_x, vels_array_y, D6)\n",
    "    #print(vels)\n",
    "    #plt.plot(D6['x_atc'], vels ,'g.', markersize=2, label='Velocity')\n",
    "\n",
    "    # load in rema and subsample\n",
    "    rema_xI,rema_yI,rema_array=tifread('./data/REMA_1km_dem_filled.tif')\n",
    "    rema_elev = get_rema_elev(rema_xI, rema_yI, rema_array, D6)\n",
    "\n",
    "    # plot results\n",
    "    # plot a map\n",
    "    #plt.close('all')\n",
    "    plotMap(D6_list, beam)\n",
    "    plotRes(D6_list, T6_list, beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "b=5\n",
    "beams=['1l(w)', '1r(s)', '2l(w)', '2r(s)', '3l(w)', '3r(s)']\n",
    "print(\"Choosing beam:\", beams[b])\n",
    "plotMap(D6_list, b)\n",
    "plotRes(D6_list, T6_list, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotRes(D6_list, T6_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl.plot()\n",
    "plt.plot([0,0], [1000000, 1000000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = gl.geometry\n",
    "gm\n",
    "#coords = np.squeeze(np.dstack((xp,yp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " rema_xI,rema_yI,rema_array=tifread('./data/REMA_1km_dem_filled.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psx,psy = pyproj.transform(lon_lat,polar_stereo,D6['longitude'],D6['latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rema_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = rema_xI[0][0], rema_xI[0][-1], rema_yI[-1][0], rema_yI[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.close('all')\n",
    "fm, axm = plt.subplots()\n",
    "im = axm.imshow(rema_array, extent=ext, cmap=\"coolwarm\", vmin=0, vmax=2500)\n",
    "axm.set_xlim(-2.5e6, -1e6)\n",
    "axm.set_ylim(-1e6, .5e6)\n",
    "divider = make_axes_locatable(axm)\n",
    "cax = divider.append_axes(\"right\", size=\"2.5%\", pad=0.3)\n",
    "cb=plt.colorbar(im,cax=cax)\n",
    "axm.plot(psx, psy, color=\"black\")\n",
    "axm.plot(*poly.exterior.xy, color=\"#d47500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross, poly = findGL(D6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D6_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
